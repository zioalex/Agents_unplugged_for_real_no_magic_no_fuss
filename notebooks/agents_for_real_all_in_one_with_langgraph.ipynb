{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198b8b09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Agents for Real — Plan. Act. Deliver.**\n",
    "\n",
    "**LangChain · LangFlow · MCP (safe)**\n",
    "\n",
    "> 25‑minute live tour + code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af192819",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Agenda\n",
    "- Why agents (vs. prompts)\n",
    "- Patterns: ReAct, Planner/Executor, Graph\n",
    "- LangChain vs LangFlow: code vs visual\n",
    "- LangGraph (stateful graphs)\n",
    "- MCP: safe tools\n",
    "- Live demo + micro‑eval\n",
    "- Risks & guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420fdf7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big idea\n",
    "**Tools > Prompts.** Agents plan, call tools, and verify.\n",
    "\n",
    "**Production focus:** versioned graphs, safe tools, evals, observability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde7284",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agentic patterns\n",
    "- **ReAct** — think/act/observe\n",
    "- **Planner/Executor** — global plan across steps\n",
    "- **Graph / Multi‑agent** — parallel skills, routing, shared state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef6488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangChain vs LangFlow (practical)\n",
    "- **LangChain** (code‑first): LCEL, tests, CI/CD\n",
    "- **LangFlow** (visual): DAGs, tweak params, export JSON, REST/MCP endpoints\n",
    "- **Workflow**: ideate in LangFlow → codify in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f39e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Live demo — what you'll run\n",
    "1) Build a tiny **ReAct** agent (retriever + calculator)\n",
    "2) Call a **LangFlow** flow via REST\n",
    "3) Attach **MCP** tools to the same agent\n",
    "4) **LangGraph** mini‑pipeline (retrieve → answer + optional router)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2972837",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setup (one time)\n",
    "```bash\n",
    "pip install -U langchain langchain-openai langchain-community langchain-ollama pandas requests matplotlib\n",
    "pip install -U langflow \"mcp[cli]\" langchain-mcp-adapters langgraph\n",
    "# (Optional) Ollama: install and `ollama pull llama3.1:8b`\n",
    "```\n",
    "In the next cell, set `BACKEND = \"OPENAI\"` or `\"OLLAMA\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba3cd9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Backend config — set ONE line\n",
    "BACKEND = \"OLLAMA\"  # or \"OPENAI\"\n",
    "MODEL_OPENAI = \"gpt-4o-mini\"\n",
    "MODEL_OLLAMA = \"llama3.1:8b\"  # ensure it's pulled if using Ollama\n",
    "\n",
    "import os, json, re, math, requests, ast, operator\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "try:\n",
    "    if BACKEND == \"OPENAI\":\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        llm = ChatOpenAI(model=MODEL_OPENAI, temperature=0.2)\n",
    "    else:\n",
    "        try:\n",
    "            from langchain_community.chat_models import ChatOllama\n",
    "        except Exception:\n",
    "            from langchain_community.llms import Ollama as ChatOllama\n",
    "        llm = ChatOllama(model=MODEL_OLLAMA)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Could not initialize LLM for BACKEND={BACKEND}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa1dc5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Tiny policy corpus + tools\n",
    "POLICIES = [\n",
    "    {\"id\": \"TravelPlus-2024\", \"text\": \"TravelPlus provides coverage for business travel including delayed flights, lost baggage, and emergency medical expenses up to CHF 10,000. Personal electronics are covered if they are lost due to theft, with a deductible of CHF 200. Pure misplacement is not covered.\"},\n",
    "    {\"id\": \"DeviceCare-Pro\", \"text\": \"DeviceCare-Pro covers accidental damage to smartphones and laptops used for work. Loss or theft is covered only when a police report is filed within 48 hours. Maximum payout CHF 1,500 per device, 2 incidents per policy year.\"},\n",
    "    {\"id\": \"FleetAssist\", \"text\": \"FleetAssist covers rented vehicles during company travel. It excludes personal property inside the vehicle unless explicitly endorsed.\"},\n",
    "]\n",
    "\n",
    "def simple_search(query: str, top_k: int = 3):\n",
    "    terms = [t.lower() for t in re.findall(r\"\\w+\", query)]\n",
    "    scored = []\n",
    "    for doc in POLICIES:\n",
    "        text = doc[\"text\"].lower()\n",
    "        score = sum(text.count(t) for t in set(terms))\n",
    "        if score > 0:\n",
    "            scored.append((score, doc))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "def search_policies(query: str) -> str:\n",
    "    hits = simple_search(query, top_k=3)\n",
    "    return json.dumps({\"results\": [{\"id\": h[\"id\"], \"snippet\": h[\"text\"][:280]} for h in hits]})\n",
    "\n",
    "OPS = {ast.Add: operator.add, ast.Sub: operator.sub, ast.Mult: operator.mul, ast.Div: operator.truediv,\n",
    "       ast.Pow: operator.pow, ast.USub: operator.neg, ast.Mod: operator.mod, ast.FloorDiv: operator.floordiv}\n",
    "def _eval(node):\n",
    "    if isinstance(node, ast.Num): return node.n\n",
    "    if isinstance(node, ast.BinOp): return OPS[type(node.op)](_eval(node.left), _eval(node.right))\n",
    "    if isinstance(node, ast.UnaryOp): return OPS[type(node.op)](_eval(node.operand))\n",
    "    raise ValueError(\"Unsupported expression\")\n",
    "def calculator(expression: str) -> str:\n",
    "    try:\n",
    "        node = ast.parse(expression, mode='eval').body\n",
    "        return str(_eval(node))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"search_policies\", func=search_policies, description=\"Search a tiny policy corpus. Returns JSON.\"),\n",
    "    Tool(name=\"calculator\", func=calculator, description=\"Evaluate arithmetic like '2*(1500-200)'. Returns a number as text.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e696a3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "demo_questions = [\n",
    "    \"My work smartphone was stolen on a business trip. Is it covered, and what are the conditions?\",\n",
    "    \"If a laptop worth CHF 1,800 is accidentally damaged twice in a year under DeviceCare-Pro, what's the max total payout after any deductibles?\",\n",
    "    \"Does FleetAssist cover personal belongings inside a rental car?\"\n",
    "]\n",
    "print(\"Demo questions:\", *demo_questions, sep=\"\\n- \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbff4f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "agent.invoke(demo_questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9944fe",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "agent.invoke(demo_questions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf633cf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "agent.invoke(demo_questions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0100123",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "except Exception:\n",
    "    def display_dataframe_to_user(name, df):\n",
    "        print(f\"\\n[name={name}]\\n{df}\")\n",
    "\n",
    "def contains_all(text: str, phrases: list[str]) -> bool:\n",
    "    low = text.lower()\n",
    "    return all(p.lower() in low for p in phrases)\n",
    "\n",
    "tests = [\n",
    "    {\"q\": demo_questions[0], \"must\": [\"covered\", \"theft\", \"police\", \"48\"]},\n",
    "    {\"q\": demo_questions[2], \"must\": [\"not\", \"unless\", \"endorsed\"]},\n",
    "]\n",
    "rows = []\n",
    "for t in tests:\n",
    "    out = agent.invoke(t[\"q\"])\n",
    "    ans = out[\"output\"] if isinstance(out, dict) and \"output\" in out else str(out)\n",
    "    rows.append({\"question\": t[\"q\"], \"passed\": contains_all(ans, t[\"must\"]), \"answer\": ans})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display_dataframe_to_user(\"LangChain agent micro‑eval\", df)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d828b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangFlow — visual builder\n",
    "- Start: `langflow run --host 127.0.0.1 --port 7860`\n",
    "- Build: Chat Model → Prompt → (optional) Tool → Agent → **Play**\n",
    "- Call from Python via REST (next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee12dce",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "def run_langflow(flow_id: str, user_input: str, base_url: str = \"http://127.0.0.1:7860/api/v1\"):\n",
    "    url = f\"{base_url}/run/{flow_id}\"\n",
    "    payload = {\"input_value\": user_input, \"output_type\": \"chat\", \"input_type\": \"chat\"}\n",
    "    r = requests.post(url, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    try:\n",
    "        return data[\"outputs\"][0][\"outputs\"][0][\"results\"][\"message\"][\"text\"]\n",
    "    except Exception:\n",
    "        return json.dumps(data, indent=2)\n",
    "\n",
    "# print(run_langflow(\"YOUR_FLOW_ID\", \"Hello from the notebook!\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8eccd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCP — safe tool server\n",
    "Standardize tools; safer by design (allow‑lists, validation). We'll write a small server and attach it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bff5a8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mcp_server_code = r'''\n",
    "from __future__ import annotations\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import re, ast, operator, json\n",
    "\n",
    "OPS = {ast.Add: operator.add, ast.Sub: operator.sub, ast.Mult: operator.mul, ast.Div: operator.truediv,\n",
    "       ast.Pow: operator.pow, ast.USub: operator.neg, ast.Mod: operator.mod, ast.FloorDiv: operator.floordiv}\n",
    "def _eval(node):\n",
    "    if isinstance(node, ast.Num): return node.n\n",
    "    if isinstance(node, ast.BinOp): return OPS[type(node.op)](_eval(node.left), _eval(node.right))\n",
    "    if isinstance(node, ast.UnaryOp): return OPS[type(node.op)](_eval(node.operand))\n",
    "    raise ValueError(\"Unsupported expression\")\n",
    "\n",
    "def safe_calculator(expression: str) -> str:\n",
    "    node = ast.parse(expression, mode='eval').body\n",
    "    return str(_eval(node))\n",
    "\n",
    "POLICIES = [\n",
    "    {\"id\": \"TravelPlus-2024\", \"text\": \"TravelPlus provides coverage for business travel including delayed flights, lost baggage, and emergency medical expenses up to CHF 10,000. Personal electronics are covered if they are lost due to theft, with a deductible of CHF 200. Pure misplacement is not covered.\"},\n",
    "    {\"id\": \"DeviceCare-Pro\", \"text\": \"DeviceCare-Pro covers accidental damage to smartphones and laptops used for work. Loss or theft is covered only when a police report is filed within 48 hours. Maximum payout CHF 1,500 per device, 2 incidents per policy year.\"},\n",
    "    {\"id\": \"FleetAssist\", \"text\": \"FleetAssist covers rented vehicles during company travel. It excludes personal property inside the vehicle unless explicitly endorsed.\"},\n",
    "]\n",
    "def simple_search(query: str, top_k: int = 3):\n",
    "    terms = [t.lower() for t in re.findall(r\"\\w+\", query)]\n",
    "    scored = []\n",
    "    for doc in POLICIES:\n",
    "        text = doc[\"text\"].lower()\n",
    "        score = sum(text.count(t) for t in set(terms))\n",
    "        if score > 0:\n",
    "            scored.append((score, doc))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "mcp = FastMCP(\"SR-Policies\", stateless_http=True)\n",
    "MAX_Q = 200\n",
    "BANNED = re.compile(r\"(?i)(rm\\s|-rf|\\bimport\\b|__|eval\\(|exec\\()\")\n",
    "\n",
    "@mcp.tool()\n",
    "def secure_search_policies(query: str) -> dict:\n",
    "    if not query or len(query) > MAX_Q or BANNED.search(query or \"\"):\n",
    "        return {\"error\": \"query_rejected\"}\n",
    "    hits = simple_search(query, top_k=3)\n",
    "    return {\"results\": [{\"id\": h[\"id\"], \"snippet\": h[\"text\"][:280]} for h in hits]}\n",
    "\n",
    "@mcp.tool()\n",
    "def safe_calc(expression: str) -> str:\n",
    "    if len(expression or \"\") > 100 or BANNED.search(expression or \"\"):\n",
    "        return \"error: expression_rejected\"\n",
    "    try:\n",
    "        return safe_calculator(expression)\n",
    "    except Exception as e:\n",
    "        return f\"error: {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=3001)\n",
    "'''\n",
    "server_path = \"/mnt/data/mcp_safe_server.py\"\n",
    "with open(server_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(mcp_server_code)\n",
    "print(\"Wrote MCP server to:\", server_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf289e5f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import asyncio\n",
    "\n",
    "async def load_mcp_toolset():\n",
    "    client = MultiServerMCPClient({\n",
    "        \"sr_policies\": {\"transport\": \"streamable_http\", \"url\": \"http://127.0.0.1:3001/mcp/\"}\n",
    "    })\n",
    "    return await client.get_tools()\n",
    "\n",
    "try:\n",
    "    mcp_tools = asyncio.run(load_mcp_toolset())\n",
    "    print(\"MCP tools:\", [t.name for t in mcp_tools])\n",
    "except Exception as e:\n",
    "    print(\"Start the MCP server first. Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dead9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangGraph — stateful agent graphs\n",
    "- **State schema** → **nodes** → **edges**\n",
    "- Optional **checkpointer** (threaded memory)\n",
    "- Below: a minimal retrieve→answer pipeline using our existing `llm` + retriever.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5e99c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Install (if needed)\n",
    "```bash\n",
    "pip install -U langgraph\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd5caf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "try:\n",
    "    from langgraph.checkpoint import MemorySaver\n",
    "    checkpointer = MemorySaver()\n",
    "except Exception:\n",
    "    checkpointer = None\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "def retrieve_node(state: AgentState) -> AgentState:\n",
    "    import json as _json\n",
    "    raw = search_policies(state.get(\"question\", \"\"))\n",
    "    data = _json.loads(raw)\n",
    "    snippets = [r.get(\"snippet\",\"\") for r in data.get(\"results\", [])]\n",
    "    return {\"context\": \"\\n\\n\".join(snippets) if snippets else \"No policy hits.\"}\n",
    "\n",
    "def answer_node(state: AgentState) -> AgentState:\n",
    "    q = state.get(\"question\",\"\"); cx = state.get(\"context\",\"\")\n",
    "    prompt = (\"Use ONLY the policy snippets to answer. If insufficient, say so.\\n\\n\"\n",
    "              f\"Policy snippets:\\n{cx}\\n\\nQuestion: {q}\\n\\nAnswer:\")\n",
    "    out = llm.invoke(prompt)\n",
    "    text = getattr(out, \"content\", str(out))\n",
    "    return {\"answer\": text}\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"answer\")\n",
    "graph.add_edge(\"answer\", END)\n",
    "app = graph.compile(checkpointer=checkpointer) if checkpointer else graph.compile()\n",
    "\n",
    "print(app.invoke({\"question\": \"Does FleetAssist cover belongings in a rental car?\"}).get(\"answer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11437eb7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: add a simple router for calc-like questions\n",
    "import re\n",
    "\n",
    "def route(state: AgentState) -> str:\n",
    "    q = state.get(\"question\",\"\")\n",
    "    return \"calc\" if re.search(r\"\\bCHF\\b|\\d+\\s*[+\\-*/]\", q) else \"retrieve\"\n",
    "\n",
    "def calc_node(state: AgentState) -> AgentState:\n",
    "    q = state.get(\"question\",\"\")\n",
    "    m = re.search(r\"(\\d+[\\d\\s+\\-*/().]*)\", q)\n",
    "    expr = m.group(1) if m else None\n",
    "    out = calculator(expr) if expr else \"Error: no expression found\"\n",
    "    return {\"context\": f\"Calculated: {expr} = {out}\", \"answer\": str(out)}\n",
    "\n",
    "g2 = StateGraph(AgentState)\n",
    "g2.add_node(\"retrieve\", retrieve_node)\n",
    "g2.add_node(\"calc\", calc_node)\n",
    "g2.add_node(\"answer\", answer_node)\n",
    "g2.add_conditional_edges(START, route, {\"retrieve\": \"retrieve\", \"calc\": \"calc\"})\n",
    "g2.add_edge(\"retrieve\", \"answer\")\n",
    "g2.add_edge(\"calc\", \"answer\")\n",
    "g2.add_edge(\"answer\", END)\n",
    "app_routed = g2.compile()\n",
    "\n",
    "print(app_routed.invoke({\"question\": \"If a laptop worth CHF 1,800 is damaged twice, what's the total?\"}).get(\"answer\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf28d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Closing\n",
    "Agents are **tools-first** systems. Ship‑ready means:\n",
    "- Versioned graphs\n",
    "- Safe MCP/allow‑listed tools\n",
    "- Eval + observability\n",
    "\n",
    "**Thanks!**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
