{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b936ae23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Agents for Real — Plan. Act. Deliver.**\n",
    "\n",
    "**LangChain · LangFlow · MCP (safe)**\n",
    "\n",
    "> 25‑minute live tour + code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27203c29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Agenda\n",
    "- Why agents (vs. prompts)\n",
    "- Patterns: ReAct, Planner/Executor, Graph\n",
    "- LangChain vs LangFlow: code vs visual\n",
    "- MCP: safe, standard tools\n",
    "- Live demo + micro‑eval\n",
    "- Risks & guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73deec5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big idea\n",
    "**Tools > Prompts.** Agents plan, call tools, and verify.\n",
    "\n",
    "**Production focus:** versioned graphs, safe tools, evals, observability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089c533",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agentic patterns\n",
    "- **ReAct** — think/act/observe\n",
    "- **Planner/Executor** — global plan across steps\n",
    "- **Graph / Multi‑agent** — parallel skills, routing, shared state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2905069",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangChain vs LangFlow (practical)\n",
    "- **LangChain** (code‑first): LCEL, tests, CI/CD\n",
    "- **LangFlow** (visual): DAGs, tweak params, export JSON, REST/MCP endpoints\n",
    "- **Workflow**: ideate in LangFlow → codify in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffd2bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCP (Model Context Protocol)\n",
    "- Standardizes **tool servers** (stdio / streamable‑HTTP)\n",
    "- Safer by design: allow‑list, input validation, stateless by default\n",
    "- Works with LangChain and LangFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9a21f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Risks & guardrails\n",
    "- Prompt injection & untrusted tool output → sanitize & validate\n",
    "- Secrets & PII → never echo; vault‑backed envs\n",
    "- Observability & eval → task‑level KPIs, logging, replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccdd0b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Live demo — what you'll run\n",
    "1) Build a tiny **ReAct** agent (retriever + calculator)\n",
    "2) Call a **LangFlow** flow via REST\n",
    "3) Attach **MCP** tools to the same agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049922e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setup (one time)\n",
    "```bash\n",
    "pip install -U langchain langchain-openai langchain-community langchain-ollama pandas requests matplotlib\n",
    "pip install -U langflow \"mcp[cli]\" langchain-mcp-adapters\n",
    "# (Optional) Ollama: install and `ollama pull llama3.1:8b`\n",
    "```\n",
    "In the next cell, set `BACKEND = \"OPENAI\"` or `\"OLLAMA\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de452825",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Backend config — set ONE line\n",
    "BACKEND = \"OLLAMA\"  # or \"OPENAI\"\n",
    "MODEL_OPENAI = \"gpt-4o-mini\"\n",
    "MODEL_OLLAMA = \"llama3.1:8b\"  # ensure it's pulled if using Ollama\n",
    "\n",
    "import os, json, re, math, requests, ast, operator\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# LLM selection\n",
    "try:\n",
    "    if BACKEND == \"OPENAI\":\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        llm = ChatOpenAI(model=MODEL_OPENAI, temperature=0.2)\n",
    "    else:\n",
    "        try:\n",
    "            from langchain_community.chat_models import ChatOllama\n",
    "        except Exception:\n",
    "            from langchain_community.llms import Ollama as ChatOllama\n",
    "        llm = ChatOllama(model=MODEL_OLLAMA)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Could not initialize LLM for BACKEND={BACKEND}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32286032",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Tiny policy corpus\n",
    "POLICIES = [\n",
    "    {\n",
    "        \"id\": \"TravelPlus-2024\",\n",
    "        \"text\": (\n",
    "            \"TravelPlus provides coverage for business travel including delayed flights, lost baggage, \"\n",
    "            \"and emergency medical expenses up to CHF 10,000. Personal electronics are covered if \"\n",
    "            \"they are lost due to theft, with a deductible of CHF 200. Pure misplacement is not covered.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"DeviceCare-Pro\",\n",
    "        \"text\": (\n",
    "            \"DeviceCare-Pro covers accidental damage to smartphones and laptops used for work. \"\n",
    "            \"Loss or theft is covered only when a police report is filed within 48 hours. \"\n",
    "            \"Maximum payout CHF 1,500 per device, 2 incidents per policy year.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"FleetAssist\",\n",
    "        \"text\": (\n",
    "            \"FleetAssist covers rented vehicles during company travel. \"\n",
    "            \"It excludes personal property inside the vehicle unless explicitly endorsed.\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "def simple_search(query: str, top_k: int = 3):\n",
    "    terms = [t.lower() for t in re.findall(r\"\\w+\", query)]\n",
    "    scored = []\n",
    "    for doc in POLICIES:\n",
    "        text = doc[\"text\"].lower()\n",
    "        score = sum(text.count(t) for t in set(terms))\n",
    "        if score > 0:\n",
    "            scored.append((score, doc))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "def search_policies(query: str) -> str:\n",
    "    hits = simple_search(query, top_k=3)\n",
    "    return json.dumps({\"results\": [{\"id\": h[\"id\"], \"snippet\": h[\"text\"][:280]} for h in hits]})\n",
    "\n",
    "# Safe arithmetic evaluator\n",
    "OPS = {\n",
    "    ast.Add: operator.add, ast.Sub: operator.sub,\n",
    "    ast.Mult: operator.mul, ast.Div: operator.truediv,\n",
    "    ast.Pow: operator.pow, ast.USub: operator.neg,\n",
    "    ast.Mod: operator.mod, ast.FloorDiv: operator.floordiv\n",
    "}\n",
    "def _eval(node):\n",
    "    if isinstance(node, ast.Num): return node.n\n",
    "    if isinstance(node, ast.BinOp): return OPS[type(node.op)](_eval(node.left), _eval(node.right))\n",
    "    if isinstance(node, ast.UnaryOp): return OPS[type(node.op)](_eval(node.operand))\n",
    "    raise ValueError(\"Unsupported expression\")\n",
    "\n",
    "def calculator(expression: str) -> str:\n",
    "    try:\n",
    "        node = ast.parse(expression, mode='eval').body\n",
    "        return str(_eval(node))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"search_policies\",\n",
    "        func=search_policies,\n",
    "        description=\"Search a tiny policy corpus. Input: a short query string. Returns JSON results.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"calculator\",\n",
    "        func=calculator,\n",
    "        description=\"Evaluate basic arithmetic like '2*(1500-200)'. Input: expression string. Returns number as text.\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cd5b3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Build the ReAct-style agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "demo_questions = [\n",
    "    \"My work smartphone was stolen on a business trip. Is it covered, and what are the conditions?\",\n",
    "    \"If a laptop worth CHF 1,800 is accidentally damaged twice in a year under DeviceCare-Pro, what's the max total payout after any deductibles?\",\n",
    "    \"Does FleetAssist cover personal belongings inside a rental car?\"\n",
    "]\n",
    "print(\"Demo questions ready:\", *demo_questions, sep=\"\\n- \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601f1b0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Try Q1 live\n",
    "res = agent.invoke(demo_questions[0])\n",
    "print(\"\\nFINAL:\", res[\"output\"] if isinstance(res, dict) and \"output\" in res else res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c2835",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Try Q2 live (should call calculator)\n",
    "res2 = agent.invoke(demo_questions[1])\n",
    "print(\"\\nFINAL:\", res2[\"output\"] if isinstance(res2, dict) and \"output\" in res2 else res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42407795",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Try Q3 live\n",
    "res3 = agent.invoke(demo_questions[2])\n",
    "print(\"\\nFINAL:\", res3[\"output\"] if isinstance(res3, dict) and \"output\" in res3 else res3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ec8ca",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Micro-evaluator (2 quick checks)\n",
    "import pandas as pd\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "except Exception:\n",
    "    def display_dataframe_to_user(name, df):\n",
    "        print(f\"\\n[name={name}]\\n{df}\")\n",
    "\n",
    "def contains_all(text: str, phrases: list[str]) -> bool:\n",
    "    low = text.lower()\n",
    "    return all(p.lower() in low for p in phrases)\n",
    "\n",
    "tests = [\n",
    "    {\"q\": demo_questions[0], \"must\": [\"covered\", \"theft\", \"police\", \"48\"]},\n",
    "    {\"q\": demo_questions[2], \"must\": [\"not\", \"unless\", \"endorsed\"]},\n",
    "]\n",
    "rows = []\n",
    "for t in tests:\n",
    "    out = agent.invoke(t[\"q\"])\n",
    "    ans = out[\"output\"] if isinstance(out, dict) and \"output\" in out else str(out)\n",
    "    rows.append({\"question\": t[\"q\"], \"passed\": contains_all(ans, t[\"must\"]), \"answer\": ans})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display_dataframe_to_user(\"LangChain agent micro‑eval\", df)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776dad3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangFlow — visual builder\n",
    "- Start: `langflow run --host 127.0.0.1 --port 7860`\n",
    "- Build: Chat Model → Prompt → (optional) Tool → Agent → **Play**\n",
    "- Call from Python via REST (next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf760dc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Helper: call a LangFlow flow via REST\n",
    "import requests, json\n",
    "\n",
    "def run_langflow(flow_id: str, user_input: str, base_url: str = \"http://127.0.0.1:7860/api/v1\"):\n",
    "    url = f\"{base_url}/run/{flow_id}\"\n",
    "    payload = {\"input_value\": user_input, \"output_type\": \"chat\", \"input_type\": \"chat\"}\n",
    "    r = requests.post(url, json=payload, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    try:\n",
    "        return data[\"outputs\"][0][\"outputs\"][0][\"results\"][\"message\"][\"text\"]\n",
    "    except Exception:\n",
    "        return json.dumps(data, indent=2)\n",
    "\n",
    "# Example:\n",
    "# print(run_langflow(\"YOUR_FLOW_ID\", \"Hello from the notebook!\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d8632",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MCP — safe tool server\n",
    "We’ll write a **minimal safe server** and run it separately, then attach its tools to our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539808df",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Write a safe MCP server to disk (run this once)\n",
    "mcp_server_code = r'''\n",
    "from __future__ import annotations\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import re, ast, operator, json\n",
    "\n",
    "OPS = {\n",
    "    ast.Add: operator.add, ast.Sub: operator.sub,\n",
    "    ast.Mult: operator.mul, ast.Div: operator.truediv,\n",
    "    ast.Pow: operator.pow, ast.USub: operator.neg,\n",
    "    ast.Mod: operator.mod, ast.FloorDiv: operator.floordiv\n",
    "}\n",
    "def _eval(node):\n",
    "    if isinstance(node, ast.Num): return node.n\n",
    "    if isinstance(node, ast.BinOp): return OPS[type(node.op)](_eval(node.left), _eval(node.right))\n",
    "    if isinstance(node, ast.UnaryOp): return OPS[type(node.op)](_eval(node.operand))\n",
    "    raise ValueError(\"Unsupported expression\")\n",
    "\n",
    "def safe_calculator(expression: str) -> str:\n",
    "    node = ast.parse(expression, mode='eval').body\n",
    "    return str(_eval(node))\n",
    "\n",
    "POLICIES = [\n",
    "    {\"id\": \"TravelPlus-2024\", \"text\": \"TravelPlus provides coverage for business travel including delayed flights, lost baggage, and emergency medical expenses up to CHF 10,000. Personal electronics are covered if they are lost due to theft, with a deductible of CHF 200. Pure misplacement is not covered.\"},\n",
    "    {\"id\": \"DeviceCare-Pro\", \"text\": \"DeviceCare-Pro covers accidental damage to smartphones and laptops used for work. Loss or theft is covered only when a police report is filed within 48 hours. Maximum payout CHF 1,500 per device, 2 incidents per policy year.\"},\n",
    "    {\"id\": \"FleetAssist\", \"text\": \"FleetAssist covers rented vehicles during company travel. It excludes personal property inside the vehicle unless explicitly endorsed.\"},\n",
    "]\n",
    "def simple_search(query: str, top_k: int = 3):\n",
    "    terms = [t.lower() for t in re.findall(r\"\\w+\", query)]\n",
    "    scored = []\n",
    "    for doc in POLICIES:\n",
    "        text = doc[\"text\"].lower()\n",
    "        score = sum(text.count(t) for t in set(terms))\n",
    "        if score > 0:\n",
    "            scored.append((score, doc))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "mcp = FastMCP(\"SR-Policies\", stateless_http=True)\n",
    "MAX_Q = 200\n",
    "BANNED = re.compile(r\"(?i)(rm\\s|-rf|\\bimport\\b|__|eval\\(|exec\\()\")\n",
    "\n",
    "@mcp.tool()\n",
    "def secure_search_policies(query: str) -> dict:\n",
    "    if not query or len(query) > MAX_Q or BANNED.search(query or \"\"):\n",
    "        return {\"error\": \"query_rejected\"}\n",
    "    hits = simple_search(query, top_k=3)\n",
    "    return {\"results\": [{\"id\": h[\"id\"], \"snippet\": h[\"text\"][:280]} for h in hits]}\n",
    "\n",
    "@mcp.tool()\n",
    "def safe_calc(expression: str) -> str:\n",
    "    if len(expression or \"\") > 100 or BANNED.search(expression or \"\"):\n",
    "        return \"error: expression_rejected\"\n",
    "    try:\n",
    "        return safe_calculator(expression)\n",
    "    except Exception as e:\n",
    "        return f\"error: {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=3001)\n",
    "'''\n",
    "server_path = \"/mnt/data/mcp_safe_server.py\"\n",
    "with open(server_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(mcp_server_code)\n",
    "print(\"Wrote MCP server to:\", server_path, \"\\nRun in a terminal: python /mnt/data/mcp_safe_server.py  # http://127.0.0.1:3001/mcp/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4b7eb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Attach MCP tools to the existing LangChain agent\n",
    "# pip install -U langchain-mcp-adapters \"mcp[cli]\"\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import asyncio\n",
    "\n",
    "async def load_mcp_toolset():\n",
    "    client = MultiServerMCPClient({\n",
    "        \"sr_policies\": {\"transport\": \"streamable_http\", \"url\": \"http://127.0.0.1:3001/mcp/\"}\n",
    "    })\n",
    "    return await client.get_tools()\n",
    "\n",
    "try:\n",
    "    mcp_tools = asyncio.run(load_mcp_toolset())\n",
    "    combined_tools = tools + mcp_tools\n",
    "    agent_mcp = initialize_agent(\n",
    "        tools=combined_tools, llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True, handle_parsing_errors=True,\n",
    "    )\n",
    "    res = agent_mcp.invoke(\"Calculate total payout if two CHF 1,800 laptop claims apply. Use safe_calc.\")\n",
    "    print(\"\\nFINAL:\", res[\"output\"] if isinstance(res, dict) and \"output\" in res else res)\n",
    "    print(\"Loaded MCP tools:\", [t.name for t in mcp_tools])\n",
    "except Exception as e:\n",
    "    print(\"Note: Start the MCP server in a separate terminal before running this cell. Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489d402",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agent landscape (1‑year)\n",
    "**Size = 50% GitHub stars (log) + 30% enterprise + 20% momentum.**\n",
    "Use the next cell to regenerate or tweak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ea08f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Weighted colorful word cloud (guaranteed placement) — edit the data to tweak\n",
    "import math, random, os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path\n",
    "\n",
    "rows = [\n",
    "    (\"LangChain\", 116_000, 0.8, 0.8),\n",
    "    (\"LangGraph\", 19_000, 0.8, 0.9),\n",
    "    (\"LangFlow\", 122_000, 0.6, 0.8),\n",
    "    (\"LlamaIndex\", 44_400, 0.7, 0.7),\n",
    "    (\"Semantic Kernel\", 26_300, 0.9, 0.8),\n",
    "    (\"OpenAI Agents SDK\", 14_900, 0.9, 0.9),\n",
    "    (\"AG2 (AutoGen)\", 3_600, 0.5, 0.5),\n",
    "    (\"CrewAI\", 38_300, 0.6, 0.8),\n",
    "    (\"PydanticAI\", 12_600, 0.6, 0.8),\n",
    "    (\"Smolagents (HF)\", 23_000, 0.5, 0.8),\n",
    "    (\"Haystack\", 22_700, 0.6, 0.6),\n",
    "    (\"Strands Agents (AWS)\", 170, 0.7, 0.9),\n",
    "    (\"Google ADK\", 200, 0.9, 0.9),\n",
    "    (\"Vertex AI Agent Builder\", 0, 1.0, 0.9),\n",
    "    (\"OpenHands\", 63_700, 0.5, 0.7),\n",
    "    (\"SuperAGI\", 38_700, 0.4, 0.5),\n",
    "    (\"Langroid\", 3_706, 0.4, 0.5),\n",
    "    (\"Agency Swarm\", 3_400, 0.4, 0.5),\n",
    "]\n",
    "\n",
    "# scoring\n",
    "logs = [math.log10(s + 10) for _, s, _, _ in rows]\n",
    "mn, mx = min(logs), max(logs)\n",
    "def combined(stars, ent, mom):\n",
    "    star_score = (math.log10(stars + 10) - mn) / (mx - mn) if mx > mn else 0.5\n",
    "    return 0.5*star_score + 0.3*ent + 0.2*mom\n",
    "\n",
    "weights = {name: combined(stars, ent, mom) for (name, stars, ent, mom) in rows}\n",
    "\n",
    "# palette\n",
    "palette_large = [(140, 61, 43), (158, 60, 28), (169, 78, 46), (181, 82, 57)]\n",
    "palette_medium = [(196, 98, 45), (210, 115, 62), (191, 107, 64), (166, 106, 63), (204, 122, 59)]\n",
    "palette_small = [(74,74,74), (91,91,91), (108,108,108), (138,110,99), (127,115,107)]\n",
    "\n",
    "def pick_color(w, wmin, wmax):\n",
    "    if w >= (wmin + 0.75*(wmax - wmin)): return random.choice(palette_large)\n",
    "    if w >= (wmin + 0.50*(wmax - wmin)): return random.choice(palette_medium)\n",
    "    return random.choice(palette_small)\n",
    "\n",
    "# canvas\n",
    "W, H = 1800, 1000\n",
    "img = Image.new(\"RGBA\", (W, H), (255,255,255,255))\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# font\n",
    "font_path = None\n",
    "for p in [\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "          \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Book.ttf\",\n",
    "          \"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\"]:\n",
    "    if os.path.exists(p):\n",
    "        font_path = p; break\n",
    "if font_path is None:\n",
    "    raise RuntimeError(\"No TTF font found.\")\n",
    "\n",
    "pairs = sorted(weights.items(), key=lambda kv: kv[1], reverse=True)\n",
    "wvals = [w for _, w in pairs]; wmin, wmax = min(wvals), max(wvals)\n",
    "def size_for(w): return int(18 + (w - wmin)/(wmax - wmin + 1e-9) * (120 - 18))\n",
    "\n",
    "def inside_ellipse(x0, y0, x1, y1):\n",
    "    cx, cy = W/2, H/2; rx, ry = W*0.46, H*0.38\n",
    "    mx, my = (x0+x1)/2, (y0+y1)/2\n",
    "    return ((mx-cx)**2)/(rx**2) + ((my-cy)**2)/(ry**2) <= 1.0\n",
    "\n",
    "def intersects(a, b, pad=6):\n",
    "    ax0, ay0, ax1, ay1 = a; bx0, by0, bx1, by1 = b\n",
    "    return not (ax1+pad < bx0 or bx1+pad < ax0 or ay1+pad < by0 or by1+pad < ay0)\n",
    "\n",
    "placed_bbs, placements = [], []\n",
    "for name, w in pairs:\n",
    "    base = size_for(w); color = pick_color(w, wmin, wmax); placed=False\n",
    "    for shrink in range(0, 20):\n",
    "        size = max(16, int(base * (0.92 ** shrink)))\n",
    "        fnt = ImageFont.truetype(font_path, size=size)\n",
    "        tw, th = draw.textbbox((0,0), name, font=fnt, anchor=\"lt\")[2:4]\n",
    "        a, b = 3, 6; theta = 0.0\n",
    "        for _ in range(2400):\n",
    "            r = a + b*theta; x = int(W/2 + r*math.cos(theta)); y = int(H/2 + r*math.sin(theta)); theta += 0.15\n",
    "            x0, y0, x1, y1 = x - tw//2, y - th//2, x + tw//2, y + th//2\n",
    "            if x0 < 12 or y0 < 12 or x1 > W-12 or y1 > H-12: continue\n",
    "            if not inside_ellipse(x0, y0, x1, y1): continue\n",
    "            if any(intersects((x0,y0,x1,y1), bb) for bb in placed_bbs): continue\n",
    "            placed_bbs.append((x0,y0,x1,y1)); placements.append((name,(x,y),fnt,color)); placed=True; break\n",
    "        if placed: break\n",
    "    if not placed:\n",
    "        fnt = ImageFont.truetype(font_path, size=16); tw, th = draw.textbbox((0,0), name, font=fnt, anchor=\"lt\")[2:4]\n",
    "        for _ in range(5000):\n",
    "            import random\n",
    "            x = random.randint(50, W-50); y = random.randint(70, H-50)\n",
    "            x0, y0, x1, y1 = x - tw//2, y - th//2, x + tw//2, y + th//2\n",
    "            if any(intersects((x0,y0,x1,y1), bb) for bb in placed_bbs): continue\n",
    "            placed_bbs.append((x0,y0,x1,y1)); placements.append((name,(x,y),fnt,color)); break\n",
    "\n",
    "for name,(x,y),fnt,color in placements:\n",
    "    for dx,dy in [(-1,0),(1,0),(0,-1),(0,1)]:\n",
    "        draw.text((x+dx, y+dy), name, font=fnt, fill=(0,0,0,35), anchor=\"mm\")\n",
    "    draw.text((x, y), name, font=fnt, fill=color, anchor=\"mm\")\n",
    "\n",
    "from IPython.display import display\n",
    "display(img)\n",
    "out = Path(\"/mnt/data/agents_for_real_wordcloud_generated.png\")\n",
    "img.convert(\"RGB\").save(out)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb860e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Presenter tips\n",
    "- Keep temperature low for stability\n",
    "- Remind: *the plan lives in the scratchpad; tools do the work*\n",
    "- If a tool fails: describe the fallback, rerun the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80742bc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Closing\n",
    "Agents are **tools-first** systems. Ship‑ready means:\n",
    "- Versioned graphs\n",
    "- Safe MCP/allow‑listed tools\n",
    "- Eval + observability\n",
    "\n",
    "**Thanks!**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
